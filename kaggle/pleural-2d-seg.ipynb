{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q segmentation_models_pytorch\n!pip install -qU wandb\n!pip install -q scikit-learn==1.0\n!pip install -q segmentation-mask-overlay","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:26:07.442852Z","iopub.execute_input":"2022-11-29T01:26:07.443194Z","iopub.status.idle":"2022-11-29T01:26:37.078816Z","shell.execute_reply.started":"2022-11-29T01:26:07.443095Z","shell.execute_reply":"2022-11-29T01:26:37.077649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# utils.py","metadata":{}},{"cell_type":"code","source":"import random\nimport os\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom segmentation_mask_overlay import overlay_masks\n\ndef load_img(img_path: str) -> np.array:\n    '''Load single 2D image from np array'''\n    img = np.load(img_path)\n    img = np.tile(img[...,None], [1, 1, 1])\n    img = img.astype('float32')\n    max_num = np.max(img)\n    if max_num:\n        img/=max_num\n    return img\n\ndef load_msk(msk_path: str) -> np.array:\n    '''Load single 2D mask from np array'''\n    msk = np.load(msk_path)\n    msk = np.tile(msk[...,None], [1, 1, 1])\n    return msk\n\ndef set_seed(seed: int = 42) -> None:\n    '''Sets the seed so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n\ndef get_mask_path(image_path: str) -> str:\n    '''Get path of the mask .nii.gz file corresponding to the image path'''\n    path_list = image_path.split(\"/\")\n    path_list[-2] = \"masks\"\n    return \"/\".join(path_list)\n\ndef mask_empty(mask_path: str) -> bool:\n    '''Check if mask is empty (only 0s)'''\n    mask = np.load(mask_path)\n    return not np.any(mask)\n\ndef get_case(image_path: str) -> str:\n    '''Get case from image path'''\n    path_list = image_path.split(\"/\")\n    fname_list = path_list[-1].split(\"-\")\n    del fname_list[-1]\n    return \"-\".join(fname_list)\n\ndef get_id(image_path: str) -> str:\n    '''Get study id from image path'''\n    path_list = image_path.split(\"/\")\n    fname_list = path_list[-1]\n    return fname_list\n\ndef save_overlay(image: np.array, \n                 mask: np.array, \n                 predict: np.array = None, \n                 out_path: str = \"./sample.png\") -> None:\n    '''Save image with mask overlay'''\n    layers = []\n    layer_labels = []\n    mask = np.where(mask<0.5, 0, 1)\n    bool_mask = np.array(mask, dtype=bool)\n    layers.append(bool_mask)\n    layer_labels.append(\"mask\")\n    if isinstance(predict, np.ndarray):\n        predict = np.where(predict<0.5, 0, 1)\n        bool_predict = np.array(predict, dtype=bool)\n        layers.append(bool_predict)\n        layer_labels.append(\"predict\")\n    cmap = np.array([[0., 0., 1., 1],[1., 0., 0., 1.,]])\n    fig = overlay_masks(image, layers, labels=layer_labels, colors=cmap, mask_alpha=0.5)\n    fig.savefig(out_path, bbox_inches=\"tight\", dpi=300)\n    plt.close(fig)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:26:37.082201Z","iopub.execute_input":"2022-11-29T01:26:37.082733Z","iopub.status.idle":"2022-11-29T01:26:37.616761Z","shell.execute_reply.started":"2022-11-29T01:26:37.082697Z","shell.execute_reply":"2022-11-29T01:26:37.616027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmap = plt.cm.tab20(np.arange(2))\ncmap","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:26:37.618011Z","iopub.execute_input":"2022-11-29T01:26:37.618797Z","iopub.status.idle":"2022-11-29T01:26:37.628968Z","shell.execute_reply.started":"2022-11-29T01:26:37.618755Z","shell.execute_reply":"2022-11-29T01:26:37.628295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# loss.py","metadata":{}},{"cell_type":"code","source":"import torch\nimport segmentation_models_pytorch as smp\n\nDiceLoss    = smp.losses.DiceLoss(mode='binary')\n\ndef criterion(y_pred: torch.tensor, y_true: torch.tensor) -> torch.tensor:\n    '''The criterion to calculate loss'''\n    return DiceLoss(y_pred, y_true)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:26:37.630851Z","iopub.execute_input":"2022-11-29T01:26:37.631158Z","iopub.status.idle":"2022-11-29T01:26:40.641808Z","shell.execute_reply.started":"2022-11-29T01:26:37.631124Z","shell.execute_reply":"2022-11-29T01:26:40.640959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# dataset.py","metadata":{}},{"cell_type":"code","source":"import torch\nimport cv2\nimport albumentations as A\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\n# from utils import load_msk, load_img\n\nclass BuildDataset(torch.utils.data.Dataset):\n    '''Npy 2D dataset'''\n\n    def __init__(self,\n                 dataset_df: pd.DataFrame,\n                 label: bool = True,\n                 transforms: dict = None):\n\n        self.dataset_df = dataset_df\n        self.label = label\n        self.img_paths = dataset_df['image_path'].tolist()\n        self.msk_paths = dataset_df['mask_path'].tolist()\n        self.transforms = transforms\n\n    def __len__(self):\n        return len(self.dataset_df)\n\n    def __getitem__(self, index):\n\n        img_path = self.img_paths[index]\n        img = []\n        img = load_img(img_path)\n\n        if self.label:\n            msk_path = self.msk_paths[index]\n            msk = load_msk(msk_path)\n            if self.transforms:\n                data = self.transforms(image=img, mask=msk)\n                img = data['image']\n                msk = data['mask']\n            img = np.transpose(img, (2, 0, 1))\n            msk = np.transpose(msk, (2, 0, 1))\n            return torch.tensor(img), torch.tensor(msk)\n\n        if self.transforms:\n            data = self.transforms(image=img)\n            img = data['image']\n        img = np.transpose(img, (2, 0, 1))\n\n        return torch.tensor(img)\n\n\ndef get_transforms(cfg: object) -> dict:\n    '''Generate transforms dict based on the cfg'''\n    data_transforms = {\n        \"train\": A.Compose([\n            A.Resize(*cfg.img_size, interpolation=cv2.INTER_NEAREST),\n            A.HorizontalFlip(p=0.5),\n            A.ShiftScaleRotate(shift_limit=0.0625,\n                               scale_limit=0.05,\n                               rotate_limit=10, p=0.5),\n            A.OneOf([\n                A.GridDistortion(num_steps=5,\n                                 distort_limit=0.05,\n                                 p=1.0),\n                A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)\n            ], p=0.25),\n            A.CoarseDropout(max_holes=8,\n                            max_height=cfg.img_size[0]//20,\n                            max_width=cfg.img_size[1]//20,\n                            min_holes=5,\n                            fill_value=0,\n                            mask_fill_value=0,\n                            p=0.5),\n        ], p=1.0),\n\n        \"valid\": A.Compose([\n            A.Resize(*cfg.img_size, interpolation=cv2.INTER_NEAREST),\n        ], p=1.0)\n    }\n    return data_transforms\n\n\ndef prepare_loaders(dataset_df: pd.DataFrame, fold: int, cfg: object) -> tuple:\n    '''Create train and val dataloaders for current fold'''\n    data_transforms = get_transforms(cfg)\n    train_df = dataset_df.query(\"fold!=@fold\").reset_index(drop=True)\n    valid_df = dataset_df.query(\"fold==@fold\").reset_index(drop=True)\n    if cfg.debug:\n        train_df = train_df.head(32*5).query(\"empty==0\")\n        valid_df = valid_df.head(32*3).query(\"empty==0\")\n    train_dataset = BuildDataset(train_df, transforms=data_transforms['train'])\n    valid_dataset = BuildDataset(valid_df, transforms=data_transforms['valid'])\n\n    train_loader = DataLoader(train_dataset, batch_size=cfg.train_bs if not cfg.debug else 20,\n                              num_workers=4, shuffle=True, pin_memory=True, drop_last=False)\n    valid_loader = DataLoader(valid_dataset, batch_size=cfg.valid_bs if not cfg.debug else 20,\n                              num_workers=4, shuffle=False, pin_memory=True)\n    return train_loader, valid_loader\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:26:40.643605Z","iopub.execute_input":"2022-11-29T01:26:40.643893Z","iopub.status.idle":"2022-11-29T01:26:41.225547Z","shell.execute_reply.started":"2022-11-29T01:26:40.643854Z","shell.execute_reply":"2022-11-29T01:26:41.224747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model.py","metadata":{}},{"cell_type":"code","source":"import torch\nimport segmentation_models_pytorch as smp\n\ndef build_model(cfg: object) -> object:\n    '''Create model'''\n    model = smp.Unet(\n        encoder_name=cfg.backbone,\n        encoder_weights=\"imagenet\",\n        in_channels=1,\n        classes=cfg.num_classes,\n        activation=None,\n    )\n    model.to(cfg.device)\n    return model\n\ndef load_model(model_path: str, cfg: object) -> object:\n    '''Load model from checkpoint'''\n    model = build_model(cfg)\n    model.load_state_dict(torch.load(model_path))\n    model.eval()\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:26:41.227019Z","iopub.execute_input":"2022-11-29T01:26:41.227304Z","iopub.status.idle":"2022-11-29T01:26:41.234306Z","shell.execute_reply.started":"2022-11-29T01:26:41.227266Z","shell.execute_reply":"2022-11-29T01:26:41.233007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference.py","metadata":{}},{"cell_type":"code","source":"@torch.no_grad()\ndef predict_image(model: object,\n                  image: np.array,\n                  device: torch.cuda.device):\n    '''Single prediction of an image'''\n    image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    image = cv2.resize(image, (224,224), interpolation = cv2.INTER_AREA)\n    image = np.expand_dims(image, axis=0)\n    image = np.expand_dims(image, axis=0)\n    image_tensor = torch.tensor(image).to(device)\n    with torch.no_grad():\n        y_pred  = model(image_tensor)\n        y_pred = (nn.Sigmoid()(y_pred)>0.01).double()\n    return y_pred.detach().cpu().numpy()[0][0]","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:26:41.236099Z","iopub.execute_input":"2022-11-29T01:26:41.236376Z","iopub.status.idle":"2022-11-29T01:26:41.247529Z","shell.execute_reply.started":"2022-11-29T01:26:41.236340Z","shell.execute_reply":"2022-11-29T01:26:41.246719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# trainer.py","metadata":{}},{"cell_type":"code","source":"import gc\nimport time\nimport copy\nfrom collections import defaultdict\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.cuda import amp\nfrom torch.optim import lr_scheduler\n# from loss import criterion\n\ndef fetch_scheduler(optimizer: object, cfg: object) -> object:\n    '''Create scheduler object'''\n\n    if cfg.scheduler is None:\n        return None\n    elif cfg.scheduler == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=cfg.T_max, \n                                                   eta_min=cfg.min_lr)\n    elif cfg.scheduler == 'CosineAnnealingWarmRestarts':\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=cfg.T_0, \n                                                             eta_min=cfg.min_lr)\n    elif cfg.scheduler == 'ReduceLROnPlateau':\n        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                   mode='min',\n                                                   factor=0.1,\n                                                   patience=4,\n                                                   threshold=0.0001,\n                                                   min_lr=cfg.min_lr,)\n    elif cfg.scheduer == 'ExponentialLR':\n        scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.85)\n\n    return scheduler\n\n\ndef train_one_epoch(model: object,\n                    optimizer: object,\n                    dataloader: object,\n                    cfg: object) -> float:\n\n    '''Single epoch training loop'''\n\n    model.train()\n    scaler = amp.GradScaler()\n    dataset_size = 0\n    running_loss = 0.0\n\n    for step, (images, masks) in enumerate(dataloader):\n        images = images.to(cfg.device, dtype=torch.float)\n        masks  = masks.to(cfg.device, dtype=torch.float)\n        batch_size = images.size(0)\n\n        with amp.autocast(enabled=True):\n            y_pred = model(images)\n            loss   = criterion(y_pred, masks)\n            loss   = loss / cfg.n_accumulate\n\n        scaler.scale(loss).backward()\n\n        if (step + 1) % cfg.n_accumulate == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n\n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        epoch_loss = running_loss / dataset_size\n        current_lr = optimizer.param_groups[0]['lr']\n        \n    torch.cuda.empty_cache()\n    gc.collect()\n    return epoch_loss\n\n@torch.no_grad()\ndef valid_one_epoch(model: object,\n                    dataloader: object,\n                    scheduler: object,\n                    device: torch.cuda.device):\n    '''Single epoch training loop'''\n\n    model.eval()\n    dataset_size = 0\n    running_loss = 0.0\n    val_scores = []\n\n    for _, (images, masks) in enumerate(dataloader):\n        images  = images.to(device, dtype=torch.float)\n        masks   = masks.to(device, dtype=torch.float)\n        batch_size = images.size(0)\n        y_pred  = model(images)\n        loss    = criterion(y_pred, masks)\n        running_loss += (loss.item() * batch_size)\n        dataset_size += batch_size\n        epoch_loss = running_loss / dataset_size\n        y_pred = nn.Sigmoid()(y_pred)\n\n        val_scores.append(1-epoch_loss)\n\n        current_lr = optimizer.param_groups[0]['lr']\n\n    if scheduler is not None:\n        scheduler.step(epoch_loss)\n        \n    torch.cuda.empty_cache()\n    gc.collect()\n\n    return epoch_loss\n\ndef run_training(model: object,\n                 train_loader: torch.utils.data.DataLoader,\n                 valid_loader: torch.utils.data.DataLoader,\n                 optimizer: object,\n                 scheduler: object,\n                 cfg: object) -> tuple:\n    '''Main training loop'''\n    # To automatically log gradients\n#     if cfg.use_wandb:\n#         wandb.watch(model, log_freq=100)\n\n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_loss = np.inf\n    best_epoch = -1\n    history = defaultdict(list)\n\n    for epoch in range(1, cfg.epochs + 1):\n        gc.collect()\n        print(f'Epoch {epoch}/{cfg.epochs}')\n\n        train_loss = train_one_epoch(model,\n                                     optimizer,\n                                     train_loader,\n                                     cfg)\n        \n        val_loss = valid_one_epoch(model,\n                                   valid_loader,\n                                   scheduler,\n                                   device=cfg.device)\n\n        history['Train Loss'].append(train_loss)\n        history['Valid Loss'].append(val_loss)\n\n        # Log the metrics\n        if cfg.use_wandb:\n            wandb.log({\"Train Loss\": train_loss,\n                       \"Valid Loss\": val_loss,\n                       \"LR\":scheduler.get_last_lr()[0]\n                      })\n\n        # deep copy the model\n        if val_loss < best_loss:\n            best_epoch = epoch\n            run.summary[\"Best Epoch\"]   = best_epoch\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = f\"best_epoch-{fold:02d}.bin\"\n            torch.save(model.state_dict(), PATH)\n            # Save a model file from the current directory\n            wandb.save(PATH)\n            best_loss = val_loss\n            \n        last_model_wts = copy.deepcopy(model.state_dict())\n        PATH = f\"last_epoch-{fold:02d}.bin\"\n        torch.save(model.state_dict(), PATH)\n\n    end = time.time()\n    time_elapsed = end - start\n\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model, history, best_loss","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:26:41.248746Z","iopub.execute_input":"2022-11-29T01:26:41.249086Z","iopub.status.idle":"2022-11-29T01:26:41.450689Z","shell.execute_reply.started":"2022-11-29T01:26:41.249045Z","shell.execute_reply":"2022-11-29T01:26:41.449725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train.py","metadata":{}},{"cell_type":"code","source":"import sys\nimport glob\nimport gc\nimport json\nimport configparser\nimport torch\nimport wandb\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedGroupKFold\nimport matplotlib.pyplot as plt\n# import utils\n# from model import build_model\n# from trainer import fetch_scheduler, run_training\n# from dataset import get_transforms, prepare_loaders\n\ndef parse_config(config_path: str) -> object:\n    '''Parse config from .ini file'''\n#     config = configparser.ConfigParser()\n#     config.read(config_path)\n\n#     class CFG:\n#         '''Main config for training and logging'''\n#         seed = int(config[\"TRAIN\"][\"seed\"])\n#         debug = bool(config[\"TRAIN\"][\"debug\"])\n#         exp_name = config[\"WANDB\"][\"exp_name\"]\n#         comment = config[\"WANDB\"][\"comment\"]\n#         model_name = config[\"TRAIN\"][\"model_name\"]\n#         backbone = config[\"TRAIN\"][\"backbone\"]\n#         train_bs = int(config[\"TRAIN\"][\"train_bs\"])\n#         valid_bs = int(config[\"TRAIN\"][\"valid_bs\"])\n#         img_size = json.loads(config[\"TRAIN\"][\"img_size\"])\n#         epochs = int(config[\"TRAIN\"][\"epochs\"])\n#         lr = float(config[\"TRAIN\"][\"lr\"])\n#         scheduler = config[\"TRAIN\"][\"scheduler\"]\n#         min_lr = float(config[\"TRAIN\"][\"min_lr\"])\n#         T_max = int(30000/train_bs*epochs)+50\n#         T_0 = int(config[\"TRAIN\"][\"T_0\"])\n#         warmup_epochs = int(config[\"TRAIN\"][\"warmup_epochs\"])\n#         wd = float(config[\"TRAIN\"][\"wd\"])\n#         n_accumulate = max(1, 32//train_bs)\n#         n_fold = int(config[\"TRAIN\"][\"n_fold\"])\n#         num_classes = int(config[\"TRAIN\"][\"num_classes\"])\n#         # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#         device = 'cpu'\n#         use_wandb = config[\"WANDB\"][\"use_wandb\"]\n\n    class CFG:\n        seed          = 101\n        debug         = False # set debug=False for Full Training\n        exp_name      = 'Baselinev2'\n        comment       = 'unet-efficientnet_b1-224x224-aug2-split2'\n        model_name    = 'Unet'\n        backbone      = 'efficientnet-b1'\n        train_bs      = 128\n        valid_bs      = train_bs*2\n        img_size      = [224, 224]\n        epochs        = 15\n        lr            = 2e-3\n        scheduler     = 'CosineAnnealingLR'\n        min_lr        = 1e-6\n        T_max         = int(30000/train_bs*epochs)+50\n        T_0           = 25\n        warmup_epochs = 0\n        wd            = 1e-6\n        n_accumulate  = max(1, 32//train_bs)\n        n_fold        = 5\n        num_classes   = 1\n        device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        use_wandb = True\n        wandb_secret = '2357b81796ab7246d2282d91387ec7f03ad92114'\n\n    return CFG\n\n# if __name__ == \"__main__\":\nif True:\n    # CFG_PATH = sys.argv[1]\n    CFG_PATH = \"./default_params.ini\"\n    CFG = parse_config(CFG_PATH)\n\n    set_seed(CFG.seed)\n    gc.collect()\n\n    BASE_PATH  = '/kaggle/input/pleural-effusion'\n    image_paths = glob.glob(\"/kaggle/input/pleural-effusion/images/*.npy\")\n\n    mask_paths = [get_mask_path(x) for x in image_paths]\n    is_empty = [mask_empty(x) for x in mask_paths]\n\n    df = pd.DataFrame({\"image_path\":image_paths, \n                    \"mask_path\":mask_paths, \n                    \"empty\": is_empty})\n\n    df[\"case\"] = df[\"image_path\"].apply(get_case)\n    df[\"id\"] = df[\"image_path\"].apply(get_id)\n\n    # K-fold split\n    skf = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n    for fold, (train_idx, val_idx) in enumerate(\n        skf.split(df, df['empty'], groups = df[\"case\"])):\n        df.loc[val_idx, 'fold'] = fold\n\n    model = build_model(CFG)\n    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n    scheduler = fetch_scheduler(optimizer, CFG)\n    # Main Loop\n    data_transforms = get_transforms(CFG)\n    best_dice = -1\n    best_fold = -1\n    best_losslist = []\n    for fold in range(CFG.n_fold):\n#     Best fold \n#     fold = 3\n#     if True:\n        print(f'### Fold: {fold+1} of {CFG.n_fold}')\n        \n        if CFG.use_wandb:\n            wandb.login(key=CFG.wandb_secret)\n            anonymous = None\n            \n            run = wandb.init(project='pleural-effusion-2d-seg',\n                             config={k:v for k, v in dict(vars(CFG)).items() if '__' not in k},\n                             name=f\"fold-{fold}|dim-{CFG.img_size[0]}x{CFG.img_size[1]}|model-{CFG.model_name}\",\n                             group=CFG.comment,\n                            )\n            \n        train_loader, valid_loader = prepare_loaders(df, fold, CFG)\n        model = build_model(CFG)\n        optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.wd)\n        scheduler = fetch_scheduler(optimizer, CFG)\n        model, history, fold_best_dice = run_training(model,\n                                                      train_loader, \n                                                      valid_loader, \n                                                      optimizer, \n                                                      scheduler,\n                                                      CFG)\n        if fold_best_dice < best_dice:\n            print(f\"New best fold: {fold}\")\n            best_fold = fold\n            PATH = f\"best_epoch-all-folds.bin\"\n            torch.save(model.state_dict(), PATH)\n            wandb.save(PATH)\n            best_dice = fold_best_dice\n            best_losslist = history[\"Valid Loss\"]\n        if not os.path.exists(\"/kaggle/working/artefacts\"):\n            os.makedirs(\"/kaggle/working/artefacts\")\n        fig, ax = plt.subplots( nrows=1, ncols=1 )\n        ax.plot(best_losslist)\n        ax.title.set_text('Dice loss')\n        ax.title.set_text('Dice loss')\n        ax.set_xlabel(\"Epochs\")\n        ax.set_ylabel(\"1 - Dice\")\n        fig.savefig(\"/kaggle/working/artefacts/dice_plot.png\")\n        plt.close(fig)\n        if CFG.use_wandb:\n            run.finish()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:26:41.452076Z","iopub.execute_input":"2022-11-29T01:26:41.452361Z","iopub.status.idle":"2022-11-29T01:27:20.704235Z","shell.execute_reply.started":"2022-11-29T01:26:41.452300Z","shell.execute_reply":"2022-11-29T01:27:20.703525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Temp","metadata":{}},{"cell_type":"code","source":"best_model = load_model(f\"best_epoch-03.bin\", CFG)\n_, valid_loader = prepare_loaders(df, fold, CFG)\npreds = []\nmasks = []\nimgs = []\nfor img_batch, mask_batch in valid_loader:\n    with torch.no_grad():\n        img_batch = img_batch.to(CFG.device)\n        pred_batch = model(img_batch)\n        pred_batch = (nn.Sigmoid()(pred_batch)>0.5).double()\n    preds.append(pred_batch)\n    masks.append(mask_batch)\n    imgs.append(img_batch)\nimgs = torch.mean(torch.stack(imgs, dim=0), dim=0).cpu().detach().numpy()\npreds = torch.mean(torch.stack(preds, dim=0), dim=0).cpu().detach().numpy()\nmasks = torch.mean(torch.stack(masks, dim=0), dim=0).cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:27:20.707645Z","iopub.execute_input":"2022-11-29T01:27:20.707859Z","iopub.status.idle":"2022-11-29T01:27:23.162155Z","shell.execute_reply.started":"2022-11-29T01:27:20.707831Z","shell.execute_reply":"2022-11-29T01:27:23.161083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm /kaggle/working/artifacts/\nif not os.path.isdir(\"/kaggle/working/artifacts/\"):\n    os.makedirs(\"/kaggle/working/artifacts/\")","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:27:23.164159Z","iopub.execute_input":"2022-11-29T01:27:23.164471Z","iopub.status.idle":"2022-11-29T01:27:23.169859Z","shell.execute_reply.started":"2022-11-29T01:27:23.164436Z","shell.execute_reply":"2022-11-29T01:27:23.168839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(imgs.shape[0]):\n    img = imgs[i][0]\n    pred = preds[i][0]\n    mask = masks[i][0]\n    out_path = f\"/kaggle/working/artifacts/{i}.png\"\n    save_overlay(img, mask, pred, out_path)","metadata":{"execution":{"iopub.status.busy":"2022-11-29T01:27:23.171256Z","iopub.execute_input":"2022-11-29T01:27:23.171727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots( nrows=1, ncols=1 )\nax.plot(history[\"Valid Loss\"])\nax.set_xlabel('Epochs')\nax.set_ylabel('1 - Dice')\nax.title.set_text(\"Dice loss\")\nfig.savefig(\"/kaggle/working/dice_plot.png\")\nplt.close(fig)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# plt.imshow(masks[1][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.imshow(preds[1][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# i=1\n# img = imgs[i][0]\n# pred = preds[i][0]\n# mask = masks[i][0]\n# out_path = f\"/kaggle/working/artifacts/{i}.png\"\n# save_overlay(img, mask, pred, out_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mask = np.where(mask<0.5, 0, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.imshow(mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# bool_mask = np.array(mask, dtype=bool)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.imshow(bool_mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}